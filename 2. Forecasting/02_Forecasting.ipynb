{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Forecasting\n",
    "<img src=images/logo.png align='right' width=200>\n",
    "\n",
    "## Goal\n",
    "While understanding the structure & dynamics of existent time series data (*interpolation*) is valuable, the main goal of time series analysis is most often *forecasting* - *extrapolation* of the current dynamics into the future. There are many competing techniques that can assist us with it. This will be the focus of this notebook.\n",
    "\n",
    "## Program\n",
    "- [Test Train Split](#tts)\n",
    "- [Cross Validation and Grid Search](#cvgs)\n",
    "    - [Assignment](#as1)\n",
    "- [Choosing the right model](#crm)\n",
    "- [Summary](#sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We go back to the previously seen *household power consumption* dataset for the rest of this notebook.\n",
    "\n",
    "![](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv('data/household_power_consumption.csv', index_col='ts', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall forecast daily energy consumption.\n",
    "\n",
    "We shall only focus on the days that had no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily = (\n",
    "    power\n",
    "    .assign(missing_data=lambda df: df['consumption'].isna())\n",
    "    .resample('D')\n",
    "    .agg({'consumption': sum, 'missing_data': any})\n",
    "    .loc[lambda df: df['missing_data']!=True]\n",
    "    .drop(columns='missing_data')\n",
    ")\n",
    "power_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can engineer some features to help our forecasting. We shall also add a smoothed version of our data that we can use for comparions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily = (\n",
    "    power_daily.loc['2007 Jul':]\n",
    "    .assign(smoothed=lambda df: df['consumption'].ewm(alpha=0.05).mean(),\n",
    "            period_num=lambda df: np.arange(len(df.index)),\n",
    "            day_of_year=lambda df: df.index.dayofyear,\n",
    "            day_of_week=lambda df: df.index.dayofweek,\n",
    "            month=lambda df: df.index.month\n",
    "           )\n",
    ")\n",
    "power_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily[['consumption', 'smoothed']].plot(figsize=(18,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tts'></a>\n",
    "## Test Train Split\n",
    "\n",
    "Let's say we have a good forecasting model in mind. How do we actually evaluate its forecasting performance on time series data? In time series analysis, a special way of splitting the data into train and test parts is used:\n",
    "\n",
    "<img src=\"images/train_test.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "A fraction of the most recent observations is held out from the model training. After fitting the model, we make predictions for the period of the test data. These predictions can then be compared with the actual values that we already know.\n",
    "\n",
    "How large should the test set be? This depends on multiple factors:\n",
    "\n",
    "- how much data we initially have\n",
    "- which frequency does the data have\n",
    "- how far into the future we want to forecast\n",
    "\n",
    "Ideally, the test should be at least *as long as the maximum required forecasting horizon*. The 20% threshold, typically used in other applications, is therefore very situational in the case of time series. The longer the forecasting horizon, the more likely model predictions are to become inaccurate (as we predict based on other predictions).\n",
    "\n",
    "In practice, test train split in time series is just indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = power_daily.loc[:'2010 April']\n",
    "test = power_daily.loc['2010 May':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "train['consumption'].plot(ax=ax)\n",
    "test['consumption'].plot(ax=ax)\n",
    "ax.legend([\"train set\", \"test set\"], prop={'size': 18});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we have a good model and want to evaluate its forecasting potential in practice. We will proceed as follows:\n",
    "\n",
    "- train this model on the train set\n",
    "- make predictions for the duration of the test set\n",
    "- compare these predictions with the actual data\n",
    "\n",
    "The example below uses a linear model with the previously seen gradual seasonal filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['period_num','day_of_year']]\n",
    "y_train = train['consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RepeatingBasisFunction(n_periods=12,\n",
    "                             remainder='passthrough',\n",
    "                             column='day_of_year')\n",
    "model = Pipeline([\n",
    "    ('preprocess', rbf),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "lm = model.fit(X_train, y_train)\n",
    "power_daily['lm_pred'] = lm.predict(power_daily[['period_num','day_of_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "train[['consumption']].plot(ax=ax)\n",
    "test[['consumption']].plot(ax=ax, c='g')\n",
    "power_daily[['lm_pred']].plot(ax=ax, c='brown')\n",
    "power_daily[['smoothed']].plot(ax=ax, c='orange')\n",
    "ax.legend([\"train set\", \"test set\", \"prediction\", \"weighted moving average\"], prop={'size': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions look reasonable, but how good are they actually? In order to quantify a model's forecasting success, we need some evaluation metrics. We want to know how far off our predictions are on average.\n",
    "\n",
    "We are predicting continuous values along a time series - therefore we need metrics suitable for this:\n",
    "\n",
    "- Mean Absolute Error:   $$\\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n",
    "- Mean Squared Error:   $$\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "- Root Mean Square Error:   $$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "Let's evaluate our previous model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_test = test['consumption']\n",
    "y_pred = power_daily['lm_pred'].loc['2010 May':]\n",
    "\n",
    "MAE = round(mean_absolute_error(y_test, y_pred),2)\n",
    "MSE = round(mean_squared_error(y_test, y_pred),2)\n",
    "RMSE = round(np.sqrt(MSE),3)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')\n",
    "print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics have their pros and cons. MSE & RMSE penalize larger errors more, while the MAE weighs all errors equally. MAE & RMSE (unlike MSE) have the same measurement units as the target variable, so the value of the error metric can be directly interpreted.\n",
    "\n",
    "Judging if the error is too high is tricky and depends on the case. There are no really simple rules of thumb. \n",
    "\n",
    "It can therefore also be useful to compute the Mean Percentage Absolute Error: the average of percentage errors by which forecasts of a model differ from actual values of the quantity being forecast.\n",
    "\n",
    "- Mean Percentage Absolute Error:   $$\\frac{100\\%}{n}\\sum_{i=1}^{n}\\frac{|y_i - \\hat{y}_i|}{y_i}$$\n",
    "\n",
    "Errors lower than 5-10% off that value are often seen as a sign of a well-fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = round(mean_absolute_percentage_error(y_test, y_pred)*100,2)\n",
    "print(f'MAE: {MAE}, MAPE: {MAPE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how inaccurate is this model *actually*? What exactly do we want it to predict well? Should we punish it for missing days with power cuts or any other sources of extreme noises? Let's have a closer look at the test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "test[['consumption']].plot(ax=ax, c='g')\n",
    "power_daily[['lm_pred']].loc['2010 May':].plot(ax=ax, c='brown')\n",
    "power_daily[['smoothed']].loc['2010 May':].plot(ax=ax, c='orange')\n",
    "ax.legend([\"test set\", \"prediction\", \"weighted moving average\"], prop={'size': 11});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our smooth model misses many sudden spikes, it is quite close to the weighted rolling average after September. If we want to select a model that is good at predicting average levels rather than individual spikes, we can also directly compare its predictions to the weighted rolling average.\n",
    "\n",
    "Compared to the weighted rolling average the error levels of our model indeed look much more moderate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_smoothed = test['smoothed']\n",
    "y_pred = power_daily['lm_pred'].loc['2010 May':]\n",
    "\n",
    "MAE = round(mean_absolute_error(y_test_smoothed, y_pred),2)\n",
    "MSE = round(mean_squared_error(y_test_smoothed, y_pred),2)\n",
    "RMSE = round(np.sqrt(MSE),3)\n",
    "MAPE = round(mean_absolute_percentage_error(y_test_smoothed, y_pred)*100,2)\n",
    "\n",
    "print(f'MAE: {MAE}, MAPE: {MAPE}%, RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cvgs'></a>\n",
    "## Cross Validation & Grid Search\n",
    "\n",
    "Often we do not have a single favorite model, and instead there are multiple candidates or different variations of the same model. Ideally we want to compare them not just based on the predictions for the last few periods. This can easily lead to overfitting - just like a single train-test split with mainstream machine learning often would. A single test set in Time Series Analysis means that we are risking to select a model that is good at predicting these particular last periods, but not something somewhat different that may come afterwards.\n",
    "\n",
    "One solution is *cross validation*. Instead of having a single test set, we can have multiple splits of the data to evaluate models. With time series however cross validation is more tricky due to the chain-like nature of time series. We can neither just select random combinations of timestamps, nor can we predict past points based on future points. There is nonetheless a way to perform cross validation:\n",
    "\n",
    "<img src='images/cross_val.png' style=\"width:400px\"></a> \n",
    "\n",
    "The idea is to split the whole time series into slices that always start from the very beginning but have different end points. Each slice is then divided into a training and testing parts, with the testing set always being the same length. The training parts are then used to train the model in each slice and are evaluated on the respective test sets.\n",
    "\n",
    "Scikit-learn library has a special method for that called `TimeSeriesSplit`. After specifying our time series split, we can directly use it with *grid search* like we would in mainstream machine learning applications.\n",
    "\n",
    "\n",
    "Here is how it works in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['period_num','day_of_year']]\n",
    "y_train = train['consumption']\n",
    "\n",
    "rbf = RepeatingBasisFunction(remainder='passthrough',\n",
    "                             column='day_of_year')\n",
    "model = Pipeline([\n",
    "    ('preprocess', rbf),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'preprocess__n_periods':[4,6,12,24],\n",
    "    'model__fit_intercept':[True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "#print statement to explain the train/test split\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    print(f\"TRAIN: [{train_index.min(), train_index.max()}]\", \n",
    "         f\"TEST: [{test_index.min(), test_index.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                        param_grid=parameters, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch.fit(X_train, y_train);\n",
    "gsearch.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(gsearch.cv_results_)\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily['grid_pred'] = gsearch.predict(power_daily[['period_num','day_of_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "test[['consumption']].plot(ax=ax, c='g')\n",
    "power_daily[['grid_pred']].loc['2010 May':].plot(ax=ax, c='brown')\n",
    "power_daily[['lm_pred']].loc['2010 May':].plot(ax=ax, c='blue')\n",
    "power_daily[['smoothed']].loc['2010 May':].plot(ax=ax, c='orange')\n",
    "ax.legend([\"test set\", \"prediction gs-model\", \"prediction model\", \"weighted moving average\"], prop={'size': 11});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = power_daily['grid_pred'].loc['2010 May':]\n",
    "\n",
    "MAE = round(mean_absolute_error(y_test_smoothed, y_pred),2)\n",
    "MSE = round(mean_squared_error(y_test_smoothed, y_pred),2)\n",
    "RMSE = round(np.sqrt(MSE),3)\n",
    "\n",
    "print(f'MAE: {MAE}, MAPE: {MAPE}%, RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='as1'></a>\n",
    "## Assignment\n",
    "\n",
    "- experiment with the number of splits in *TimeSeriesSplit* and the scoring used in *GridSearch*, \n",
    "- observe whether this affects the results and our preferred model parameters and how\n",
    "- what happens if the number of splits is set too low or too high?\n",
    "- similarly, experiment with the set of parameters to choose from\n",
    "\n",
    "An example solution is given below, where for different *n_splits* the RMSEs of the best model are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/cv_splits.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crm'></a>\n",
    "## Choosing the right model\n",
    "\n",
    "### ARIMA\n",
    "**Autoregressive integrated moving average**.\n",
    "Learning about the future from recent past: variable of interest is regressed on its own lagged values. Designed for stockmarket predictions.\n",
    "\n",
    "**Pros:** \n",
    "- Can provide quite accurate short-term forecast if the data is substantially autocorrelated\n",
    "\n",
    "**Cons:** \n",
    "- Requires careful tuning and insufficient tuning can lead to a poor model. \n",
    "- Requires stationary time series: a time series whose properties do not depend on the time at which the series is observed. Thus, time series with trends, or with seasonality, are not stationary — the trend and seasonality will affect the value of the time series at different times. \n",
    "- Hard to interpret and break into quantifiable effects.\n",
    "\n",
    "---\n",
    "\n",
    "### LSTMs\n",
    "**Long short term memory neural networks**. Combine NN's flexibility with keeping track of the recent and distant past (memory cells)\n",
    "\n",
    "**Pros:** \n",
    "- Flexible and does not require much preprocessing and parameter tuning. \n",
    "- Can exploit complex dependencies in time series\n",
    "\n",
    "**Cons:** \n",
    "- Prone to over-fitting. \n",
    "- Training requires large datasets. \n",
    "- Even harder to interpret than ARIMA\n",
    "\n",
    "---\n",
    "\n",
    "### Prophet\n",
    "Forecasting time series data by explicitly modeling trends, seasonalities and holiday effects - especially suitable for business applications.\n",
    "\n",
    "**Pros:** \n",
    "- Highly automated and simple to use. \n",
    "- Does not require extensive preprocessing and domain knowledge. \n",
    "- Robust to missing data, outliers and dramatic changes. \n",
    "- Measures explainable and quantifiable effects. \n",
    "- Can be easily used to detect outliers and trend change points. \n",
    "- Typically outperforms many custom models.\n",
    "\n",
    "**Cons:** \n",
    "- Is a bit of a black box. \n",
    "- Still in development and some features are still missing. \n",
    "- Less customization of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sum'></a>\n",
    "## Summary\n",
    "\n",
    "We have covered: \n",
    "\n",
    "- How to forecast and evaluate predictions.\n",
    "- How to conduct a hyperparameter grid search for forecasting.\n",
    "- The advantages/disadvantages of popular forecasting models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
